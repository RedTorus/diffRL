_wandb:
    value:
        cli_version: 0.19.9
        m:
            - "1": steps
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": episode
              "6": []
              "7": []
            - "1": critic_loss
              "5": 4
              "6":
                - 1
                - 3
              "7": []
            - "1": step
              "6": []
              "7": []
            - "1": actor_loss
              "5": 4
              "6":
                - 1
                - 3
              "7": []
            - "1": reward
              "5": 2
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.9.18
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 7
                - 13
                - 16
                - 23
                - 55
            "4": 3.9.18
            "5": 0.19.9
            "8":
                - 5
            "10":
                - 20
            "12": 0.19.9
            "13": linux-x86_64
ac_grad_norm:
    value: 2
action_gradient_steps:
    value: 20
action_lr:
    value: 0.03
agent:
    value: ddiffpg
alpha_mean:
    value: 0.001
alpha_std:
    value: 0.001
aug:
    value: false
batch_size:
    value: 256
behavior_sample:
    value: 4
beta:
    value: 1
beta_schedule:
    value: cosine
chosen:
    value: 1
critic_lr:
    value: 0.0003
cuda:
    value: cuda:0
cut:
    value: 1
deterministic:
    value: false
diffusion_lr:
    value: 0.0001
diffusion_mode:
    value: ddpm
entropy_alpha:
    value: 0.02
env_name:
    value: HalfCheetah-v3
epsilon:
    value: 0
eval_sample:
    value: 32
gamma:
    value: 0.99
gradient:
    value: false
n_timesteps:
    value: 20
noise_ratio:
    value: 1
num_steps:
    value: 500000
policy_freq:
    value: 1
policy_type:
    value: Diffusion
q_neg:
    value: 0
q_transform:
    value: qadv
ratio:
    value: 0.1
seed:
    value: 0
target_sample:
    value: 4
tau:
    value: 0.005
times:
    value: 1
train_sample:
    value: 64
update_actor_target_every:
    value: 1
use_wandb:
    value: true
weighted:
    value: false
